<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NLP Concept Visualizer</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        .container {
            max-width: 800px;
            margin: auto;
        }
        textarea {
            width: 100%;
            height: 100px;
            margin-bottom: 20px;
        }
        button {
            display: block;
            margin-bottom: 20px;
        }
        .result {
            margin-top: 20px;
        }
        .section {
            margin-bottom: 20px;
        }
        .highlight {
            background-color: #f0f8ff;
            padding: 2px 5px;
            border-radius: 3px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 10px;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: center;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>NLP Concept Visualizer</h1>
        <textarea id="inputText" placeholder="Type or paste your sentence here..."></textarea>
        <button onclick="processText()">Process</button>
        <div class="result" id="result"></div>
    </div>

    <script>
        // Basic tokenization function
        function tokenize(text) {
            return text.split(/[\s,.;!?]+/).filter(token => token.length > 0);
        }

        // Basic stemming function (mockup)
        function stem(token) {
            return token.toLowerCase().replace(/(ing|ed|s)$/i, '');
        }

        // Basic lemmatization function (mockup)
        function lemmatize(token) {
            return token.toLowerCase().replace(/(ies)$/i, 'y').replace(/(ing|ed|s)$/i, '');
        }

        // Bag of Words function
        function bagOfWords(tokens) {
            let wordCount = {};
            tokens.forEach(token => {
                const lowerToken = token.toLowerCase();
                wordCount[lowerToken] = (wordCount[lowerToken] || 0) + 1;
            });
            return wordCount;
        }

        // TF-IDF calculation
        function calculateTFIDF(tokens, totalDocuments = 1) {
            let wordCount = bagOfWords(tokens);
            let tfidf = {};
            let tokenSet = new Set(tokens.map(token => token.toLowerCase()));

            for (const word of tokenSet) {
                const tf = wordCount[word] / tokens.length; // Term Frequency
                const idf = Math.log(totalDocuments / 1) + 1; // Inverse Document Frequency; simplified to 1 document + smoothing
                tfidf[word] = tf * idf;
            }
            return tfidf;
        }

        function displayResults(tokens, stemmedTokens, lemmatizedTokens, bow, tfidf) {
            let resultContainer = document.getElementById('result');
            resultContainer.innerHTML = `
                <div class="section">
                    <h2>Tokenization</h2>
                    <p>Tokenization breaks the input sentence into smaller pieces called tokens. These are often words or terms. Below are the tokens identified in the sentence:</p>
                    <p>${tokens.map(token => `<span class="highlight">${token}</span>`).join(' ')}</p>
                </div>
                <div class="section">
                    <h2>Stemming</h2>
                    <p>Stemming reduces each word to its base or root form. This process might not result in actual words, but it helps in normalizing similar words to a common base.</p>
                    <p>${stemmedTokens.map(token => `<span class="highlight">${token}</span>`).join(' ')}</p>
                </div>
                <div class="section">
                    <h2>Lemmatization</h2>
                    <p>Lemmatization reduces words to their dictionary or base form. Unlike stemming, lemmatization results in valid words.</p>
                    <p>${lemmatizedTokens.map(token => `<span class="highlight">${token}</span>`).join(' ')}</p>
                </div>
                <div class="section">
                    <h2>Bag of Words</h2>
                    <p>The Bag of Words model counts how many times each word appears in the sentence. This representation ignores the order of words but captures their frequency.</p>
                    <table>
                        <tr>
                            <th>Word</th>
                            <th>Frequency</th>
                        </tr>
                        ${Object.entries(bow).map(([word, freq]) => `
                            <tr>
                                <td>${word}</td>
                                <td>${freq}</td>
                            </tr>`).join('')}
                    </table>
                </div>
                <div class="section">
                    <h2>TF-IDF</h2>
                    <p>TF-IDF (Term Frequency-Inverse Document Frequency) measures the importance of a word in a sentence relative to a corpus. TF shows how frequently a word appears, and IDF reduces the weight of common words by calculating the inverse frequency across documents.</p>
                    <table>
                        <tr>
                            <th>Word</th>
                            <th>TF-IDF Score</th>
                        </tr>
                        ${Object.entries(tfidf).map(([word, score]) => `
                            <tr>
                                <td>${word}</td>
                                <td>${score.toFixed(4)}</td>
                            </tr>`).join('')}
                    </table>
                </div>
            `;
        }

        function processText() {
            let inputText = document.getElementById('inputText').value;
            if (inputText.trim() === '') {
                alert('Please enter a sentence.');
                return;
            }

            const tokens = tokenize(inputText);
            const stemmedTokens = tokens.map(stem);
            const lemmatizedTokens = tokens.map(lemmatize);
            const bow = bagOfWords(tokens);
            const tfidf = calculateTFIDF(tokens);

            displayResults(tokens, stemmedTokens, lemmatizedTokens, bow, tfidf);
        }
    </script>
</body>
</html>
